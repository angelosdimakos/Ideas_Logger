import os
from typing import Any, Dict, List, Tuple

from scripts.ai.llm_router import get_prompt_template, apply_persona
from scripts.ai.module_docstring_summarizer import summarize_module
from scripts.unified_code_assistant.analysis import analyze_report
from scripts.unified_code_assistant.prompt_builder import build_contextual_prompt, build_enhanced_contextual_prompt
from scripts.unified_code_assistant.assistant_utils import get_issue_locations
from scripts.unified_code_assistant.module_summarizer import summarize_modules
from scripts.ai.llm_refactor_advisor import build_refactor_prompt
from scripts.unified_code_assistant import cli_entrypoint
import tempfile
import json

class AIIntegration:
    def __init__(self, config, summarizer):
        """
        Initializes the AIIntegration instance with configuration and summarizer components.
        """
        self.config = config
        self.summarizer = summarizer

    def generate_audit_summary(self, metrics_context: str) -> str:
        """
        Generates an AI-driven audit summary based on provided metrics context.
        
        Combines a persona-enriched audit summary prompt with the given metrics context and returns a summarized audit report as a string.
        """
        prompt = get_prompt_template("Audit Summary", self.config)
        final_prompt = apply_persona(prompt, self.config.persona)
        enriched = final_prompt + "\n\n" + metrics_context
        return self.summarizer.summarize_entry(enriched, subcategory="Audit Summary")

    def generate_refactor_advice(self, merged_data, limit: int):
        """
        Generates AI-driven refactoring advice based on analysis of merged code data.
        
        Analyzes the provided merged data to identify the top offenders for refactoring, constructs a contextual prompt, and returns a summary suggestion along with the list of top offenders.
        
        Args:
            merged_data: Aggregated code analysis data to be evaluated.
            limit: The maximum number of top offenders to consider.
        
        Returns:
            A tuple containing the AI-generated refactor suggestion and the list of top offenders.
        """
        analysis = analyze_report(merged_data, top_n=limit)
        prompt = build_contextual_prompt(
            "What needs refactoring?",
            analysis["top_offenders"],
            analysis["summary_metrics"],
            self.config.persona
        )
        suggestion = self.summarizer.summarize_entry(prompt, subcategory="Refactor Advisor")
        return suggestion, analysis["top_offenders"]

    def generate_strategic_recommendations(self, merged_data, limit: int = 30):
        """
        Generates strategic recommendations based on merged code analysis data.
        
        Writes the merged data to a temporary JSON file and invokes a CLI assistant in strategic mode with the specified limit and persona. Returns the output generated by the CLI assistant.
        
        Args:
            merged_data: The combined code analysis data to be evaluated.
            limit: The maximum number of recommendations to generate.
        
        Returns:
            The output string containing strategic recommendations.
        """
        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
            json.dump(merged_data, f)
            f.flush()
            args = ["assistant", f.name, "--mode", "strategic", "--top", str(limit), "--persona", self.config.persona]
            return cli_entrypoint.call_cli_for_output(args)

    def chat_general(self, user_query, merged_data):
        """
        Generates an AI-driven summary response to a user query based on analyzed code report data.
        
        Args:
            user_query: The user's question or prompt for the AI.
            merged_data: Aggregated code analysis data to inform the response.
        
        Returns:
            A summary string providing advice or insights relevant to the user query and code analysis context.
        """
        analysis = analyze_report(merged_data)
        prompt = build_contextual_prompt(user_query, analysis["top_offenders"], analysis["summary_metrics"], self.config.persona)
        return self.summarizer.summarize_entry(prompt, subcategory="Risk Advisor Chat")

    def chat_code(self, file_path, complexity_info, lint_info, user_query):
        """
        Generates an AI-driven code analysis summary for a specific file based on user input.
        
        Builds a detailed context using the file's complexity and linting information, issue locations, placeholder module summaries, and AI-generated refactor recommendations. Incorporates the user's query and persona to produce a comprehensive code analysis summary for the file.
        
        Args:
            file_path: Path to the file being analyzed.
            complexity_info: Complexity metrics or data for the file.
            lint_info: Linting quality information for the file.
            user_query: User's question or prompt related to the file.
        
        Returns:
            A summarized AI-generated analysis of the file in response to the user query.
        """
        offender_tuple = (file_path, None, [], 1, 5, 0.8)
        report_data = {
            file_path: {
                "coverage": {"complexity": complexity_info},
                "linting": {"quality": lint_info}
            }
        }

        file_issues = {
            file_path: get_issue_locations(file_path, report_data)
        }

        module_summaries = {
            file_path: "Module summary not available"
        }

        refactor_prompt = build_refactor_prompt(
            [offender_tuple],
            self.config,
            subcategory="Refactor Advisor",
            verbose=False,
            limit=1
        )
        file_recommendations = {
            file_path: self.summarizer.summarize_entry(refactor_prompt, subcategory="Tooling & Automation")
        }

        contextual_prompt = build_enhanced_contextual_prompt(
            user_query,
            [offender_tuple],
            summary_metrics={"coverage": "unknown"},
            module_summaries=module_summaries,
            file_issues=file_issues,
            file_recommendations=file_recommendations,
            persona=self.config.persona
        )

        return self.summarizer.summarize_entry(contextual_prompt, subcategory="Code Analysis")

    def chat_doc(self, module_path, funcs):
        """
        Generates a summary of a module's documentation using the provided functions list.
        
        Args:
            module_path: Path to the module to be summarized.
            funcs: List of functions within the module to include in the summary.
        
        Returns:
            A summary string describing the module and its functions.
        """
        return summarize_module(module_path, funcs, self.summarizer, self.config)
