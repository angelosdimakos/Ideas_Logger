# Zephyrus Idea Logger ğŸ§ ğŸ“

A powerful, AI-integrated idea capture and summarization tool designed for:
- Narrative design
- Worldbuilding
- AI system architecture
- Research logging

Zephyrus combines a streamlined GUI, automated local LLM summarization, and lightning-fast semantic search via FAISS.

---

## âœ¨ Features

- â¬œ **Clean GUI:** Log structured entries using dropdowns for category/subcategory.
- ğŸ¤– **AI Summarization:** Automatically summarizes every 5 entries per subcategory (via local Ollama).
- âš–ï¸ **Correction System:** Lets you manually revise summaries, with both `original_summary` and `corrected_summary` saved.
- ğŸ” **FAISS Vector Search:** Search your summaries semantically using cosine similarity.
- ğŸ“… **Time-Aware Batching:** Entries are grouped per date and subcategory, each with metadata.
- ğŸ“ƒ **Obsidian-Ready:** Markdown export enabled for seamless PKM workflows.

---

## âš¡ Quickstart

```bash
# 1. Clone the repo
$ git clone https://github.com/YOUR_USERNAME/zephyrus-idea-logger.git
$ cd zephyrus-idea-logger

# 2. Create virtual env & install dependencies
$ python -m venv venv && source venv/bin/activate
$ pip install -r requirements.txt

# 3. Launch the GUI
$ python scripts/main.py
```

---

## ğŸ“ How It Works

### Logging
- Choose a main category and subcategory
- Type your idea and save
- Every 5 entries: AI generates a summary, saved to `correction_summaries.json`

### Summarization
- Uses `llama3` or your configured Ollama model
- Summaries stored alongside original entries
- Manual corrections are versioned and stored as `corrected_summary`

### Search
- FAISS indexes all summaries
- You can rebuild the index and search via GUI
- Supports batch + metadata display for fast context

### Double Linking
- Each summary knows which log entries it came from
- Entries can be traced back via their `log_YYYYMMDD_###` ID

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py                # Entry point
â”‚   â”œâ”€â”€ gui.py                 # Full Tkinter GUI
â”‚   â”œâ”€â”€ core.py                # Handles saving logs + summaries
â”‚   â”œâ”€â”€ ai_summarizer.py      # Local LLM-based summarizer
â”‚   â”œâ”€â”€ summary_indexer.py    # FAISS summary search logic
â”‚   â”œâ”€â”€ raw_log_indexer.py    # FAISS indexing for raw log content
â”‚   â”œâ”€â”€ base_indexer.py       # Shared FAISS logic
â”‚   â”œâ”€â”€ config_loader.py      # Handles config.json loading
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ zephyrus_log.json     # Main idea log
â”‚   â””â”€â”€ correction_summaries.json  # Summary metadata
â”œâ”€â”€ exports/                      # Obsidian-compatible .md output
â”œâ”€â”€ vector_store/                # FAISS index and metadata
â”œâ”€â”€ config.json                  # All app configuration
```

---

## ğŸš€ Configuration

All behavior is controlled via `config.json`:

```json
"summarization": true,
"llm_model": "llama3",
"batch_size": 5,
"correction_summaries_path": "logs/correction_summaries.json",
"json_log_file": "logs/zephyrus_log.json"
```

> âš ï¸ You must have **Ollama** installed and the selected model available locally.

---

## ğŸ“ Testing

```bash
# Coming soon - tests for:
# - Summarization logic
# - FAISS index build/search
# - Data structure validation
```

---

## âœ¨ Roadmap

- [x] GUI Logger w/ Dropdowns
- [x] AI Summarization via Ollama
- [x] FAISS Vector Search (Summaries)
- [x] Correction + Double Link Tracking
- [ ] Raw Log Vector Search
- [ ] Plugin Support (Obsidian + Exports)
- [ ] Automated Testing & CLI

---

## ğŸ™Œ Contributing

Pull requests, ideas, and feature suggestions welcome!
- Fork + PR
- Raise an issue
- Or DM me if you want to collaborate deeper!

---

## ğŸ“„ License

MIT License. Use it freely, but don't resell without giving credit.

---

Built with â¤ï¸ by Angelos Dimakos and his sentient AI archivist.

